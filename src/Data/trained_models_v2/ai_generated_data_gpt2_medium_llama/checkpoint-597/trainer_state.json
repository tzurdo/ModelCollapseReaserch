{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 597,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.050314465408805034,
      "grad_norm": 0.5680152773857117,
      "learning_rate": 3.6e-05,
      "loss": 2.1747,
      "step": 10
    },
    {
      "epoch": 0.10062893081761007,
      "grad_norm": 0.5113649368286133,
      "learning_rate": 7.6e-05,
      "loss": 2.1157,
      "step": 20
    },
    {
      "epoch": 0.1509433962264151,
      "grad_norm": 0.6758726239204407,
      "learning_rate": 0.000116,
      "loss": 1.9524,
      "step": 30
    },
    {
      "epoch": 0.20125786163522014,
      "grad_norm": 0.5351372361183167,
      "learning_rate": 0.00015600000000000002,
      "loss": 1.8892,
      "step": 40
    },
    {
      "epoch": 0.25157232704402516,
      "grad_norm": 0.6372619867324829,
      "learning_rate": 0.000196,
      "loss": 1.8909,
      "step": 50
    },
    {
      "epoch": 0.3018867924528302,
      "grad_norm": 0.570414125919342,
      "learning_rate": 0.000196709323583181,
      "loss": 1.8733,
      "step": 60
    },
    {
      "epoch": 0.3522012578616352,
      "grad_norm": 0.5889348983764648,
      "learning_rate": 0.00019305301645338208,
      "loss": 1.8999,
      "step": 70
    },
    {
      "epoch": 0.4025157232704403,
      "grad_norm": 0.532134473323822,
      "learning_rate": 0.0001893967093235832,
      "loss": 1.8407,
      "step": 80
    },
    {
      "epoch": 0.4528301886792453,
      "grad_norm": 0.5863614082336426,
      "learning_rate": 0.0001857404021937843,
      "loss": 1.8517,
      "step": 90
    },
    {
      "epoch": 0.5031446540880503,
      "grad_norm": 0.5169705152511597,
      "learning_rate": 0.00018208409506398538,
      "loss": 1.8329,
      "step": 100
    },
    {
      "epoch": 0.5534591194968553,
      "grad_norm": 0.5369712114334106,
      "learning_rate": 0.00017842778793418648,
      "loss": 1.84,
      "step": 110
    },
    {
      "epoch": 0.6037735849056604,
      "grad_norm": 0.5129629969596863,
      "learning_rate": 0.00017477148080438757,
      "loss": 1.8591,
      "step": 120
    },
    {
      "epoch": 0.6540880503144654,
      "grad_norm": 0.5349016785621643,
      "learning_rate": 0.00017111517367458866,
      "loss": 1.8538,
      "step": 130
    },
    {
      "epoch": 0.7044025157232704,
      "grad_norm": 0.5360409617424011,
      "learning_rate": 0.00016745886654478978,
      "loss": 1.8466,
      "step": 140
    },
    {
      "epoch": 0.7547169811320755,
      "grad_norm": 0.5104203224182129,
      "learning_rate": 0.00016380255941499087,
      "loss": 1.8615,
      "step": 150
    },
    {
      "epoch": 0.8050314465408805,
      "grad_norm": 0.5337590575218201,
      "learning_rate": 0.00016014625228519196,
      "loss": 1.8454,
      "step": 160
    },
    {
      "epoch": 0.8553459119496856,
      "grad_norm": 0.4949369728565216,
      "learning_rate": 0.00015648994515539305,
      "loss": 1.8235,
      "step": 170
    },
    {
      "epoch": 0.9056603773584906,
      "grad_norm": 0.5067936778068542,
      "learning_rate": 0.00015283363802559417,
      "loss": 1.8702,
      "step": 180
    },
    {
      "epoch": 0.9559748427672956,
      "grad_norm": 0.49905893206596375,
      "learning_rate": 0.00014917733089579526,
      "loss": 1.8324,
      "step": 190
    },
    {
      "epoch": 1.0050314465408805,
      "grad_norm": 0.5107911825180054,
      "learning_rate": 0.00014552102376599635,
      "loss": 1.8086,
      "step": 200
    },
    {
      "epoch": 1.0553459119496855,
      "grad_norm": 0.4912390410900116,
      "learning_rate": 0.00014186471663619744,
      "loss": 1.7641,
      "step": 210
    },
    {
      "epoch": 1.1056603773584905,
      "grad_norm": 0.6786510944366455,
      "learning_rate": 0.00013820840950639856,
      "loss": 1.8439,
      "step": 220
    },
    {
      "epoch": 1.1559748427672956,
      "grad_norm": 0.5787385106086731,
      "learning_rate": 0.00013455210237659962,
      "loss": 1.7782,
      "step": 230
    },
    {
      "epoch": 1.2062893081761006,
      "grad_norm": 0.5000531077384949,
      "learning_rate": 0.00013089579524680074,
      "loss": 1.7963,
      "step": 240
    },
    {
      "epoch": 1.2566037735849056,
      "grad_norm": 0.6007251143455505,
      "learning_rate": 0.00012723948811700183,
      "loss": 1.794,
      "step": 250
    },
    {
      "epoch": 1.3069182389937106,
      "grad_norm": 0.6177252531051636,
      "learning_rate": 0.00012358318098720295,
      "loss": 1.7846,
      "step": 260
    },
    {
      "epoch": 1.3572327044025156,
      "grad_norm": 0.5812760591506958,
      "learning_rate": 0.00011992687385740402,
      "loss": 1.7789,
      "step": 270
    },
    {
      "epoch": 1.4075471698113207,
      "grad_norm": 0.5901986360549927,
      "learning_rate": 0.00011627056672760512,
      "loss": 1.7978,
      "step": 280
    },
    {
      "epoch": 1.4578616352201257,
      "grad_norm": 0.5798575282096863,
      "learning_rate": 0.00011261425959780623,
      "loss": 1.7816,
      "step": 290
    },
    {
      "epoch": 1.5081761006289307,
      "grad_norm": 0.6308135390281677,
      "learning_rate": 0.0001089579524680073,
      "loss": 1.8103,
      "step": 300
    },
    {
      "epoch": 1.5584905660377357,
      "grad_norm": 0.5477752089500427,
      "learning_rate": 0.00010530164533820841,
      "loss": 1.8315,
      "step": 310
    },
    {
      "epoch": 1.6088050314465407,
      "grad_norm": 0.5926520824432373,
      "learning_rate": 0.00010164533820840951,
      "loss": 1.7532,
      "step": 320
    },
    {
      "epoch": 1.6591194968553458,
      "grad_norm": 0.5966628789901733,
      "learning_rate": 9.79890310786106e-05,
      "loss": 1.7222,
      "step": 330
    },
    {
      "epoch": 1.7094339622641508,
      "grad_norm": 0.6184054613113403,
      "learning_rate": 9.433272394881171e-05,
      "loss": 1.8292,
      "step": 340
    },
    {
      "epoch": 1.759748427672956,
      "grad_norm": 0.5908905863761902,
      "learning_rate": 9.06764168190128e-05,
      "loss": 1.772,
      "step": 350
    },
    {
      "epoch": 1.810062893081761,
      "grad_norm": 0.6180363893508911,
      "learning_rate": 8.70201096892139e-05,
      "loss": 1.7725,
      "step": 360
    },
    {
      "epoch": 1.860377358490566,
      "grad_norm": 0.5728508830070496,
      "learning_rate": 8.3363802559415e-05,
      "loss": 1.8402,
      "step": 370
    },
    {
      "epoch": 1.910691823899371,
      "grad_norm": 0.5929386019706726,
      "learning_rate": 7.97074954296161e-05,
      "loss": 1.7357,
      "step": 380
    },
    {
      "epoch": 1.961006289308176,
      "grad_norm": 0.5571984052658081,
      "learning_rate": 7.60511882998172e-05,
      "loss": 1.8039,
      "step": 390
    },
    {
      "epoch": 2.010062893081761,
      "grad_norm": 0.5876564383506775,
      "learning_rate": 7.239488117001828e-05,
      "loss": 1.804,
      "step": 400
    },
    {
      "epoch": 2.060377358490566,
      "grad_norm": 0.6107373833656311,
      "learning_rate": 6.873857404021939e-05,
      "loss": 1.6762,
      "step": 410
    },
    {
      "epoch": 2.110691823899371,
      "grad_norm": 0.5946477651596069,
      "learning_rate": 6.508226691042048e-05,
      "loss": 1.7321,
      "step": 420
    },
    {
      "epoch": 2.161006289308176,
      "grad_norm": 0.6531806588172913,
      "learning_rate": 6.142595978062157e-05,
      "loss": 1.7476,
      "step": 430
    },
    {
      "epoch": 2.211320754716981,
      "grad_norm": 0.6178305745124817,
      "learning_rate": 5.776965265082267e-05,
      "loss": 1.7232,
      "step": 440
    },
    {
      "epoch": 2.261635220125786,
      "grad_norm": 0.6351026296615601,
      "learning_rate": 5.4113345521023775e-05,
      "loss": 1.7525,
      "step": 450
    },
    {
      "epoch": 2.311949685534591,
      "grad_norm": 0.6006114482879639,
      "learning_rate": 5.0457038391224866e-05,
      "loss": 1.7418,
      "step": 460
    },
    {
      "epoch": 2.362264150943396,
      "grad_norm": 0.5950251221656799,
      "learning_rate": 4.6800731261425964e-05,
      "loss": 1.7374,
      "step": 470
    },
    {
      "epoch": 2.412578616352201,
      "grad_norm": 0.66750168800354,
      "learning_rate": 4.314442413162706e-05,
      "loss": 1.7712,
      "step": 480
    },
    {
      "epoch": 2.462893081761006,
      "grad_norm": 0.6437432765960693,
      "learning_rate": 3.948811700182815e-05,
      "loss": 1.7463,
      "step": 490
    },
    {
      "epoch": 2.513207547169811,
      "grad_norm": 0.6105210185050964,
      "learning_rate": 3.583180987202925e-05,
      "loss": 1.7356,
      "step": 500
    },
    {
      "epoch": 2.5635220125786162,
      "grad_norm": 0.5886884331703186,
      "learning_rate": 3.217550274223035e-05,
      "loss": 1.7257,
      "step": 510
    },
    {
      "epoch": 2.6138364779874212,
      "grad_norm": 0.6395742893218994,
      "learning_rate": 2.8519195612431444e-05,
      "loss": 1.7705,
      "step": 520
    },
    {
      "epoch": 2.6641509433962263,
      "grad_norm": 0.6894236207008362,
      "learning_rate": 2.4862888482632542e-05,
      "loss": 1.7271,
      "step": 530
    },
    {
      "epoch": 2.7144654088050313,
      "grad_norm": 0.6991498470306396,
      "learning_rate": 2.1206581352833637e-05,
      "loss": 1.7452,
      "step": 540
    },
    {
      "epoch": 2.7647798742138363,
      "grad_norm": 0.6299497485160828,
      "learning_rate": 1.7550274223034735e-05,
      "loss": 1.7503,
      "step": 550
    },
    {
      "epoch": 2.8150943396226413,
      "grad_norm": 0.6500961780548096,
      "learning_rate": 1.3893967093235833e-05,
      "loss": 1.7559,
      "step": 560
    },
    {
      "epoch": 2.8654088050314463,
      "grad_norm": 0.6471724510192871,
      "learning_rate": 1.023765996343693e-05,
      "loss": 1.693,
      "step": 570
    },
    {
      "epoch": 2.9157232704402514,
      "grad_norm": 0.7301071286201477,
      "learning_rate": 6.5813528336380256e-06,
      "loss": 1.7735,
      "step": 580
    },
    {
      "epoch": 2.9660377358490564,
      "grad_norm": 0.658444881439209,
      "learning_rate": 2.9250457038391228e-06,
      "loss": 1.737,
      "step": 590
    }
  ],
  "logging_steps": 10,
  "max_steps": 597,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.861975042260992e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
